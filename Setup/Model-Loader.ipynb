{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7baa10db",
   "metadata": {},
   "source": [
    "# Performing Image Classification with a Saved Model\n",
    "\n",
    "### Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8c8baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6789546",
   "metadata": {},
   "source": [
    "### Step 2: Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c74581fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['identifiable', 'unidentifiable']\n",
    "img_size = 224\n",
    "\n",
    "def get_data(data_dir):\n",
    "    \"\"\"Return a numpy array\n",
    "\n",
    "    Numpy array containing train or testing set data values. Read the images from \n",
    "    data_dir in the RGB format and resize the images to the desired width and height.\n",
    "    \"\"\"\n",
    "    data = [] \n",
    "    for label in labels: \n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label) # 0: identifiable, 1: unidentifiable\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img))[...,::-1] #convert BGR to RGB format\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
    "                data.append([resized_arr, class_num])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return np.array(data, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e7b5877",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object is not subscriptable\n",
      "'NoneType' object is not subscriptable\n",
      "'NoneType' object is not subscriptable\n",
      "'NoneType' object is not subscriptable\n"
     ]
    }
   ],
   "source": [
    "# Fetch the train and validation data.\n",
    "train = get_data('../images dataset/Training Set')\n",
    "val = get_data('../images dataset/Testing Set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709085c2",
   "metadata": {},
   "source": [
    "### Step 3: Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "124b1bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "for feature, label in train:\n",
    "  x_train.append(feature)\n",
    "  y_train.append(label)\n",
    "\n",
    "for feature, label in val:\n",
    "  x_val.append(feature)\n",
    "  y_val.append(label)\n",
    "\n",
    "# Normalize the data\n",
    "x_train = np.array(x_train) / 255\n",
    "x_val = np.array(x_val) / 255\n",
    "\n",
    "x_train.reshape(-1, img_size, img_size, 1)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_val.reshape(-1, img_size, img_size, 1)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes, dtype='int64')\n",
    "y_val_original = y_val\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes, dtype='int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c6a158",
   "metadata": {},
   "source": [
    "### Step 4: Load and Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4edaea09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "  Identifiable (Class 0)       0.98      0.98      0.98       197\n",
      "Unidentifiable (Class 1)       0.98      0.98      0.98       198\n",
      "\n",
      "                accuracy                           0.98       395\n",
      "               macro avg       0.98      0.98      0.98       395\n",
      "            weighted avg       0.98      0.98      0.98       395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading Model\n",
    "new_model = tf.keras.models.load_model('../saved_model/model_v1')\n",
    "\n",
    "# Checking Loaded Model\n",
    "saved_predictions = np.argmax(new_model.predict(x_val), axis=-1)\n",
    "saved_predictions = saved_predictions.reshape(1,-1)[0]\n",
    "\n",
    "print(classification_report(y_val_original, saved_predictions, target_names = ['Identifiable (Class 0)','Unidentifiable (Class 1)']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
